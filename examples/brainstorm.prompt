<workflow initial="routing">
    <datamodel>
        <data id="user_id" expr="null" />
        <data id="initialState" expr="null" />
        <data id="llm_output" expr="null" />
        <data id="issueNotes" expr="[]" />
    </datamodel>

    <!-- {/* Initial state router */}  -->
    <state id="routing">
        <log label="routing-preprocessing" expr="`chatHistory is \${JSON.stringify(chatHistory)}`" />
        <llm
            model="accounts/fireworks/models/qwen2p5-72b-instruct"
            instructions="\${context.systemPrompt}"
            input="You are an agent responsible for orchestrating to the right specialized agent.
                You have the following agents specializes in their tasks:
                - meet_and_greet: this agent specializes in authenticate the user. You should
                route to this agent until the user is authenticated even if the user has other
            requests.
                - cancel_order: this agent specializes in helping users cancel or return an
                existing order
                - modify_order: this agent specializes in helping users modify or exchange an
            existing order
                - select_products: this agent specializes in helping users select products or
            specific product types to buy.
                - profile_management: this agent specializes in helping users manage or update
                their profile
                - human_agent: this is a human agent that can handle anything other agents can't
                handle or when no specific agent specializes in such user request.
                - good_bye: this agent should come in when the user wants to end the
                conversation, it's sending goodbye messages to the user.
                Here is the chat history:
                ## Chat_history
                \${JSON.stringify(chatHistory)}
                ## End_of Chat_history
                Please judge which agent you should route to and call the function to state it."
            tools= {[
            {
            name: 'next_state' ,
            description:
                    'Choose the next state to transition to. You should always pass in all required parameters for the next state.' ,
            parameters: {
            type: "object" ,
            required: ["thought_process" , "next_state" ],
            properties: {
            thought_process: {
            type: "string" ,
            description: "The thought process to decide on the next state"
            },
            next_state: {
            type: "string" ,
            enum: [
                                "meet_and_greet" ,
                                "cancel_order" , 
                                "modify_order" ,
                                "profile_management" ,
                                "select_products" ,
                                "human_agent" ,
                                "good_bye"
            ],
            description: "The next state to transition to"
            }
            }
            }
            }]
            toolChoice="required"
        />
        <assign location="initialState" expr="input?.args?.next_state" />

        <transition cond="initialState === 'meet_and_greet'" target="meet_and_greet" />
        <transition cond="initialState === 'cancel_order'" target="cancel_order" />
        <transition cond="initialState === 'modify_order'" target="modify_order" />
        <transition cond="initialState === 'get_order_details'" target="get_order_details" />
        <transition cond="initialState === 'profile_management'" target="profile_management" />
        <transition cond="initialState === 'human_agent'" target="human_agent" />
        <transition cond="initialState === 'good_bye'" target="good_bye" />
        <transition target="error" />
    </state>

    <state id="meet_and_greet">
        <state id="meet_and_greet-llm">
            <llm
                model="accounts/fireworks/models/qwen2p5-72b-instruct"
                input="\${userInput.text}"
                instructions="You are a retail agent. Your first task is to authenticate the user by
                locating their user id via email. If the user did not provide an email, directly
                respond with a pecific message 'email not found'."
                tools= {[
                {
                name: 'find_user_id_by_email' ,
                description: 'Find user id by email. If the user did not provide an email, do not call the function' ,
                parameters: {
                type: "object" ,
                required: ["email" ],
                properties: {
                email: {
                type: "string" ,
                description: "The email to find the user by"
                }
                }
                }
                },
                {
                name: 'find_user_id_by_name_zip' ,
                description:
                'Find user id by first name, last name, and zip code. If the user is not found, the function will return an error message. By default, find user id by email, and only call this function if the user is not found by email or cannot remember email.' ,
                parameters: {
                type: "object" ,
                required: ["first_name" , "last_name" , "zip" ],
                properties: {
                first_name: {
                type: "string" ,
                description: "The first name of the user"
                },
                last_name: {
                type: "string" ,
                description: "The last name of the user"
                },
                zip: {
                type: "string" ,
                description: "The zip code of the user"
                }
                }
                }
                }
                ]}
            />

            <transition cond="input?.args?.user_id" target="meet_and_greet-user_id_found" />
            <transition target="meet_and_greet-request_user_id" />
        </state>
        <state id="meet_and_greet-user_id_found">
            <llm
                mockResponse='{"role": "assistant", "content": "Thanks for confirming, we found your user id is 123456, and we now can proceed with your request."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="meet_and_greet-request_user_id">
            <llm
                mockResponse='{"role": "assistant", "content": "Could you provide your registered email or user id for us to proceed?"}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
    </state>

    <state id="cancel_order" initial="cancel_order-llm">
        <state id="cancel_order-llm">
            <llm
                model="accounts/fireworks/models/qwen2p5-72b-instruct"
                includeChatHistory= {true}
                input="\${userInput.text}"
                instructions="You are a retail agent responsible for helping the user cancel their order.
                Your current task is to help the user cancel their order by parsing through chat
                history to identify critical information and then leveraging tools to execute the
                task.
                If you don't have the right information, request it from the user."
                tools= {[
                {
                name: 'cancel_pending_order' ,
                description: 'Cancel the order with the given order id' ,
                parameters: {
                type: "object" ,
                required: ["order_id" ],
                properties: {
                order_id: {
                type: "string" ,
                description: "The order id to cancel"
                }
                }
                }
                },
                {
                name: 'get_order_details' ,
                description: 'Get the status and details of an order.' ,
                parameters: {
                type: "object" ,
                required: ["order_id" ],
                properties: {
                order_id: {
                type: "string" ,
                description: "The order id to get details for"
                }
                }
                }
                },
                {
                name: 'transfer_to_human_agents' ,
                description: 'Transfer the user to a human agent, with a summary of the issue.' ,
                parameters: {
                type: "object" ,
                required: ["summary" ],
                properties: {
                summary: {
                type: "string" ,
                description: "A summary of the issue"
                }
                }
                }
                },
                {
                name: 'request_more_info' ,
                description:
                'When you do not have enough information, use this tool to request more information from the user.' ,
                parameters: {
                type: "object" ,
                required: ["info" ],
                properties: {
                info: {
                type: "string" ,
                enum: ["order_id" ],
                description: "the information you need the user to provide"
                }
                }
                }
                }
                ]}
                toolChoice="required"
            />

            <assign location="llm_output" expr="input" />
            <if cond="input?.toolName === 'request_more_info' && input.args?.info === 'order_id">
                <transition target="cancel_order-requesting_order_id" />
                <elseif cond="input?.toolName === 'get_order_details'">
                    <transition target="get_order_details" />
                </elseif>
                <elseif cond="input?.toolName === 'transfer_to_human_agents'">
                    <assign
                        location="issueNotes"
                        expr="[...issueNotes, {assistant: 'cancel_order', summary: input?.args?.summary || ''}]"
                    />
                    <transition target="human_agent" />
                </elseif>
                <elseif cond="input?.toolName === 'cancel_pending_order'">
                    <transition target="cancel_order-success" />
                </elseif>
                <else>
                    <transition target="cancel_order-error" />
                </else>
            </if>
        </state>
        <state id="cancel_order-requesting_order_id">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the order id for the order you want to cancel."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="cancel_order-success">
            <llm
                mockResponse='{"role": "assistant", "content": "Great, your order has been cancelled successfully."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="cancel_order-error">
            <llm
                mockResponse='{"role": "assistant", "content": "We are sorry, but we are having trouble processing your request. Please try again later."}'
                mockResponseType="json"
            />
            <transition target="error" />
        </state>
    </state>

    <state id="modify_order" initial="modify_order-llm">
        <state id="modify_order-llm">
            <llm
                model="accounts/fireworks/models/qwen2p5-72b-instruct"
                includeChatHistory= {true}
                input="\${userInput.text}"
                instructions="You are a retail agent responsible for helping the user modify their order.
                Your current task is to help the user modify their order by parsing through chat
                history to identify critical information and then leveraging tools to execute the
                task.
                If you don't have the right information, request it from the user."
                tools= {[
                {
                name: 'modify_pending_order_address' ,
                description: 'Modify the address of the order with the given order id' ,
                parameters: {
                type: "object" ,
                required: ["order_id" , "address" ],
                properties: {
                order_id: {
                type: "string" ,
                description: "The order id to modify"
                },
                address: {
                type: "string" ,
                description: "The address to modify the order to"
                }
                }
                }
                },
                {
                name: 'modify_pending_order_items' ,
                description: 'Modify the items of the order with the given order id' ,
                parameters: {
                type: "object" ,
                required: ["order_id" , "items" ],
                properties: {
                order_id: {
                type: "string" ,
                description: "The order id to modify"
                },
                items: {
                type: "array" ,
                description: "The items to modify the order to" ,
                items: {
                type: "object" ,
                required: ["product_id" , "quantity" ],
                properties: {
                product_id: {
                type: "string" ,
                description: "The product id to modify"
                },
                quantity: {
                type: "number" ,
                description: "The quantity of the product to modify"
                }
                }
                }
                }
                }
                }
                },
                {
                name: 'get_order_details' ,
                description: 'Get the status and details of an order.' ,
                parameters: {
                type: "object" ,
                required: ["order_id" ],
                properties: {
                order_id: {
                type: "string" ,
                description: "The order id to get details for"
                }
                }
                }
                },
                {
                name: 'transfer_to_human_agents' ,
                description: 'Transfer the user to a human agent, with a summary of the issue.' ,
                parameters: {
                type: "object" ,
                required: ["summary" ],
                properties: {
                summary: {
                type: "string" ,
                description: "A summary of the issue"
                }
                }
                }
                },
                {
                name: 'request_more_info' ,
                description:
                'When you do not have enough information, use this tool to request more information from the user.' ,
                parameters: {
                type: "object" ,
                required: ["info" ],
                properties: {
                info: {
                type: "string" ,
                enum: ["order_id" , "new_address" , "updated_items" ],
                description: "the information you need the user to provide"
                }
                }
                }
                }
                ]}
                toolChoice="required"
            />
            <assign location="llm_output" expr="input" />
            <if cond="input?.toolName === 'request_more_info'">
                <if cond="input.args?.info === 'order_id'">
                    <transition target="modify_order-requesting_order_id" />
                    <elseif cond="input.args?.info === 'new_address'" />
                    <transition target="modify_order-requesting_new_address" />
                    <elseif cond="input.args?.info === 'updated_items'" />
                    <transition target="modify_order-requesting_updated_items" />
                </if>
                <elseif cond="input?.toolName === 'get_order_details'" />
                <transition target="get_order_details" />
                <elseif cond="input?.toolName === 'transfer_to_human_agents'" />
                <assign
                    location="issueNotes"
                    expr="[...issueNotes, {assistant: 'modify_order', summary: input?.args?.summary || ''}]"
                />
                <transition target="human_agent" />
                <elseif
                    cond="input?.toolName === 'modify_pending_order_address' || input?.toolName === 'modify_pending_order_items'" />
                <transition target="modify_order-success" />
                <else />
                <transition target="modify_order-error" />
            </if>
        </state>
        <state id="modify_order-requesting_order_id">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the order id for the order you want to modify."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="modify_order-requesting_new_address">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the new address for the order you want to modify."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="modify_order-requesting_updated_items">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the updated items for the order you want to modify."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="modify_order-success">
            <llm
                mockResponse='{"role": "assistant", "content": "Great, your order has been modified successfully."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="modify_order-error">
            <llm
                mockResponse='{"role": "assistant", "content": "We are sorry, but we are having trouble processing your request. Please try again later."}'
                mockResponseType="json"
            />
            <transition target="error" />
        </state>
    </state>
    <state id="profile_management" initial="profile_management-llm">
        <state id="profile_management-llm">
            <llm
                model="accounts/fireworks/models/qwen2p5-72b-instruct"
                includeChatHistory= {true}
                input="\${userInput.text}"
                tools= {[
                {
                name: 'modify_user_address' ,
                description: 'Update the user address with the given information' ,
                parameters: {
                type: "object" ,
                required: ["user_id" , "address" ],
                properties: {
                user_id: {
                type: "string" ,
                description: "The user id to update"
                },
                address: {
                type: "string" ,
                description: "The address to update the user to"
                }
                }
                }
                },
                {
                name: 'get_user_details' ,
                description: 'Get the details of the user with the given user id' ,
                parameters: {
                type: "object" ,
                required: ["user_id" ],
                properties: {
                user_id: {
                type: "string" ,
                description: "The user id to get details for"
                }
                }
                }
                },
                {
                name: 'transfer_to_human_agents' ,
                description: 'Transfer the user to a human agent, with a summary of the issue.' ,
                parameters: {
                type: "object" ,
                required: ["summary" ],
                properties: {
                summary: {
                type: "string" ,
                description: "A summary of the issue"
                }
                }
                }
                },
                {
                name: 'request_more_info' ,
                description:
                'When you do not have enough information, use this tool to request more information from the user.' ,
                parameters: {
                type: "object" ,
                required: ["info" ],
                properties: {
                info: {
                type: "string" ,
                enum: ["user_id" , "new_address" ],
                description: "the information you need the user to provide"
                }
                }
                }
                }
                ]}
                toolChoice="required"
            >
                <instructions>
                    You are a retail agent responsible for helping the user update their profile.
                    Your current task is to help the user update their profile by parsing through
                    chat
                    history to
                    identify critical information and then leveraging tools to execute the task.
                    If you don't have the right information, request it from the user.
                </instructions>
            </llm>
            <assign location="llm_output" expr="input" />
            <if cond="input?.toolName === 'request_more_info'">
                <if cond="input.args?.info === 'user_id'">
                    <transition target="profile_management-requesting_user_id" />
                    <elseif cond="input.args?.info === 'new_address'" />
                    <transition target="profile_management-requesting_new_address" />
                </if>
                <elseif cond="input?.toolName === 'get_user_details'" />
                <transition target="profile_management-get_user_details" />
                <elseif cond="input?.toolName === 'transfer_to_human_agents'" />
                <assign
                    location="issueNotes"
                    expr="[...issueNotes, {assistant: 'profile_management', summary: input?.args?.summary || ''}]"
                />
                <transition target="human_agent" />
                <elseif cond="input?.toolName === 'modify_user_address'" />
                <transition target="profile_management-success" />
                <else />
                <transition target="profile_management-error" />
            </if>
        </state>
        <state id="profile_management-requesting_user_id">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the user id for the user you want to update."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="profile_management-requesting_new_address">
            <llm
                mockResponse='{"role": "assistant", "content": "Please provide the new address for the user you want to update."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="profile_management-success">
            <llm
                mockResponse='{"role": "assistant", "content": "Great, your order has been modified successfully."}'
                mockResponseType="json"
            />
            <transition target="back_to_user" />
        </state>
        <state id="profile_management-error">
            <llm
                mockResponse='{"role": "assistant", "content": "We are sorry, but we are having trouble processing your request. Please try again later."}'
                mockResponseType="json"
            />
            <transition target="error" />
        </state>
    </state>

    <state id="human_agent">
        <llm
            model="accounts/fireworks/models/qwen2p5-72b-instruct"
            includeChatHistory= {true}
            input="\${userInput.text}"
            instructions="You are a human agent responsible for helping the user with their comprehensive
            issues after other AI agents have failed to resolve the issue.
            The summarized issues by different AI agents are provided below:
            \${JSON.stringify(issueNotes)}
            You should engage with the user to further understand the issue and provide a
            solution."
        />
        <assign location="llm_output" expr="input" />
        <transition target="back_to_user" />
    </state>

    <state id="select_products">
        <llm
            mockResponse='{"role": "assistant", "content": "The products are currently pending."}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <state id="get_order_details">
        <llm
            mockResponse='{"role": "assistant", "content": "The order id R-123456 is currently pending."}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <state id="get_product_details">
        <llm
            mockResponse='{"role": "assistant", "content": "The product id P-123456 is currently pending."}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <state id="get_user_details">
        <llm
            mockResponse='{"role": "assistant", "content": "The user id U-123456 is currently pending."}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <state id="list_all_product_types">
        <llm
            mockResponse='{"role": "assistant", "content": "The product types are currently pending."}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <state id="good_bye">
        <llm
            mockResponse='{"role": "assistant", "content": "Thank you for using our service. Goodbye!"}'
            mockResponseType="json"
        />
        <transition target="back_to_user" />
    </state>

    <final id="back_to_user" />
    <final id="error">
        <llm
            mockResponse= {`{"role" : "assistant" , "content" : "I'm sorry, but I'm having trouble processing your request. Please try again later." }`}
            mockResponseType="json"
        />
    </final>
</workflow>