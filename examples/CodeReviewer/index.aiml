---
name: CodeReviewerAssistant
inputSchema:
  type: object
  properties:
    repositoryUrl:
      type: string
      description: URL of the repository to review
    pullRequestId:
      type: string
      description: Pull request ID to review
    reviewDepth:
      type: string
      enum: ["basic", "standard", "deep"]
      default: "standard"
      description: Depth of the code review
    focusAreas:
      type: array
      items:
        type: string
      description: Areas to focus on in the review (e.g., security, performance)
root: true
---

{/* 
This implements an automated code reviewer that can analyze pull requests,
identify issues, and provide detailed feedback. It aims to mimic a thorough human
code review process with multiple specialized analyses.

The workflow fetches code from a repository, performs various analyses including
security scanning, performance evaluation, code quality assessment, and test coverage.
It then synthesizes findings into actionable feedback organized by priority and category.

This can help development teams maintain code quality without manual review overhead.
*/}

import SecurityRules from "./SecurityRules.json"
import CodeQualityRules from "./CodeQualityRules.json"
import TestingTools from "./testingtools.js"

<workflow initial="fetchCode">
  <datamodel>
    <data id="repositoryUrl" type="string">{ctx.workflowInput.repositoryUrl}</data>
    <data id="pullRequestId" type="string">{ctx.workflowInput.pullRequestId}</data>
    <data id="reviewDepth" type="string">{ctx.workflowInput.reviewDepth || "standard"}</data>
    <data id="focusAreas" type="array">{ctx.workflowInput.focusAreas || []}</data>
    <data id="codeFiles" type="json" value={{}} />
    <data id="diffStats" type="json" value={{}} />
    <data id="securityFindings" type="array" value={[]} />
    <data id="qualityIssues" type="array" value={[]} />
    <data id="performanceIssues" type="array" value={[]} />
    <data id="testCoverage" type="json" value={{}} />
    <data id="reviewSummary" type="string" value={""} />
    <data id="recommendations" type="array" value={[]} />
    <data id="reviewComments" type="json" value={{}} />
  </datamodel>

  <state id="fetchCode">
    <script>{`
      // Prepare for fetching code
      ctx.log("Preparing to fetch code from repository");
    `}</script>
      
    <toolcall name="gitFetch">
      <param name="repoUrl" value={(ctx) => ctx.datamodel.repositoryUrl} />
      <param name="prId" value={(ctx) => ctx.datamodel.pullRequestId} />
    </toolcall>
      
    <script>{`
      try {
        const result = ctx.lastElement.output;
        ctx.datamodel.codeFiles = result.files;
        ctx.datamodel.diffStats = result.stats;
      } catch (e) {
        ctx.log("Error fetching code: " + e.message);
        ctx.datamodel.codeFiles = {};
        ctx.datamodel.diffStats = { additions: 0, deletions: 0, filesChanged: 0, error: true };
      }
    `}</script>
      
    <log value={(ctx) => 'Fetched ' + ctx.datamodel.diffStats.filesChanged + ' files with ' + ctx.datamodel.diffStats.additions + ' additions and ' + ctx.datamodel.diffStats.deletions + ' deletions'} />
    <transition target="securityAnalysis" />
  </state>

  <state id="securityAnalysis">
      <script>{`
        // Load security rules
        const securityRules = JSON.parse(SecurityRules);
        const filesToAnalyze = Object.entries(ctx.datamodel.codeFiles);
        
        // Filter security rules based on focus areas if specified
        let activeRules = securityRules;
        if (ctx.datamodel.focusAreas.length > 0) {
          activeRules = securityRules.filter(rule => 
            ctx.datamodel.focusAreas.some(area => rule.categories.includes(area))
          );
        }
        
        // Adjust analysis depth based on reviewDepth
        const depthMultiplier = {
          "basic": 0.5,
          "standard": 1.0,
          "deep": 1.5
        }[ctx.datamodel.reviewDepth] || 1.0;
        
        // Only analyze a subset of files for basic reviews
        const filesToCheck = 
          ctx.datamodel.reviewDepth === "basic" && filesToAnalyze.length > 5 
            ? filesToAnalyze.slice(0, 5) 
            : filesToAnalyze;
            
        ctx.log(`Security analysis beginning with ${activeRules.length} rules on ${filesToCheck.length} files`);
        
        // Mock security scanning (in a real system, this would use actual scanners)
        ctx.datamodel.securityFindings = [];
        for (const [filename, content] of filesToCheck) {
          for (const rule of activeRules) {
            if (content.toLowerCase().includes(rule.pattern.toLowerCase())) {
              ctx.datamodel.securityFindings.push({
                filename: filename,
                line: content.split('\n').findIndex(line => 
                  line.toLowerCase().includes(rule.pattern.toLowerCase())
                ) + 1,
                rule: rule.id,
                severity: rule.severity,
                description: rule.description,
                suggestion: rule.suggestion
              });
            }
          }
        }
      `}</script>
      <log value={(ctx) => 'Security analysis complete. Found ' + ctx.datamodel.securityFindings.length + ' potential issues'} />
      <transition target="codeQualityAnalysis" />
  </state>

  <state id="codeQualityAnalysis">
      <script>{`
        // Load code quality rules
        const qualityRules = JSON.parse(CodeQualityRules);
        const filesToAnalyze = Object.entries(ctx.datamodel.codeFiles);
        
        // Filter quality rules based on focus areas if specified
        let activeRules = qualityRules;
        if (ctx.datamodel.focusAreas.length > 0) {
          activeRules = qualityRules.filter(rule => 
            ctx.datamodel.focusAreas.some(area => rule.categories.includes(area))
          );
        }
        
        // Adjust analysis depth based on reviewDepth
        const depthMultiplier = {
          "basic": 0.5,
          "standard": 1.0,
          "deep": 1.5
        }[ctx.datamodel.reviewDepth] || 1.0;
        
        // Mock code quality scanning
        ctx.datamodel.qualityIssues = [];
        for (const [filename, content] of filesToAnalyze) {
          // Skip non-code files
          const isCodeFile = /\.(js|ts|py|java|c|cpp|cs|go|rb|php)$/i.test(filename);
          if (!isCodeFile) continue;
          
          for (const rule of activeRules) {
            if (content.toLowerCase().includes(rule.pattern.toLowerCase())) {
              ctx.datamodel.qualityIssues.push({
                filename: filename,
                line: content.split('\n').findIndex(line => 
                  line.toLowerCase().includes(rule.pattern.toLowerCase())
                ) + 1,
                rule: rule.id,
                severity: rule.severity,
                description: rule.description,
                suggestion: rule.suggestion
              });
            }
          }
        }
      `}</script>
      <log value={(ctx) => 'Code quality analysis complete. Found ' + ctx.datamodel.qualityIssues.length + ' issues'} />
      <transition target="performanceAnalysis" />
  </state>

  <state id="performanceAnalysis">
      <script>{`
        // Functions to analyze performance
        function analyzeComplexity(code) {
          // Simple complexity estimation by counting nested blocks and loops
          const nestingCount = (code.match(/\{/g) || []).length;
          const loopCount = (code.match(/for\s*\(|while\s*\(|forEach|map\s*\(/g) || []).length;
          
          return Math.min(10, Math.floor((nestingCount + loopCount) / 5));
        }
        
        function analyzeDataStructures(code) {
          // Check for inefficient data structure usage
          const inefficientPatterns = [
            { pattern: /\.indexOf\(.+\)\s*!==/g, issue: "Linear search in array" },
            { pattern: /for\s*\(.+\s+in\s+/g, issue: "Iterating object keys" },
            { pattern: /new\s+Array\(\d+\)/g, issue: "Pre-allocated array" }
          ];
          
          return inefficientPatterns
            .filter(p => p.pattern.test(code))
            .map(p => p.issue);
        }
        
        // Analyze all code files for performance issues
        ctx.datamodel.performanceIssues = [];
        for (const [filename, content] of Object.entries(ctx.datamodel.codeFiles)) {
          // Skip non-code files
          const isCodeFile = /\.(js|ts|py|java|c|cpp|cs|go|rb|php)$/i.test(filename);
          if (!isCodeFile) continue;
          
          const complexity = analyzeComplexity(content);
          if (complexity > 5) {
            ctx.datamodel.performanceIssues.push({
              filename: filename,
              type: "complexity",
              severity: complexity > 8 ? "high" : "medium",
              description: `High cyclomatic complexity (estimated: ${complexity}/10)`,
              suggestion: "Consider breaking down complex functions into smaller, more manageable pieces."
            });
          }
          
          const dataIssues = analyzeDataStructures(content);
          for (const issue of dataIssues) {
            ctx.datamodel.performanceIssues.push({
              filename: filename,
              type: "data-structure",
              severity: "medium",
              description: `Potentially inefficient data structure usage: ${issue}`,
              suggestion: "Consider using more appropriate data structures or algorithms for this operation."
            });
          }
        }
      `}</script>
      <log value={(ctx) => 'Performance analysis complete. Found ' + ctx.datamodel.performanceIssues.length + ' issues'} />
      <transition target="testCoverageAnalysis" />
  </state>

  <state id="testCoverageAnalysis">
    <script>{`
      // Mock test coverage analysis
      try {
        const testingToolCode = TestingTools;
        // Execute the code
        const mockTestAnalyzer = eval(`(${testingToolCode})`);
        ctx.datamodel.testCoverage = mockTestAnalyzer.analyzeCoverage(ctx.datamodel.codeFiles);
      } catch (e) {
        ctx.log("Error analyzing test coverage: " + e.message);
        ctx.datamodel.testCoverage = {
          overall: 0,
          byFile: {},
          issues: [
            { 
              description: "Error analyzing test coverage", 
              severity: "medium",
              suggestion: "Ensure test files are properly formatted and located"
            }
          ]
        };
      }
    `}</script>
    <log value={(ctx) => 'Test coverage analysis complete. Overall coverage: ' + (ctx.datamodel.testCoverage.overall || 0) + '%'} />
    <transition target="synthesizeFindings" />
  </state>

  <state id="synthesizeFindings">
      <llm model="gpt-4o" temperature={0.1}>
        <prompt>
          You are a professional code reviewer who specializes in providing actionable feedback. 
          Based on the following findings from automated analysis tools, generate a concise but 
          comprehensive code review summary highlighting the most important issues. Your 
          summary should be respectful, constructive, and highlight both strengths and areas 
          for improvement.
          
          Pull Request Statistics:
          - Files changed: {ctx.datamodel.diffStats.filesChanged || 0}
          - Lines added: {ctx.datamodel.diffStats.additions || 0}
          - Lines removed: {ctx.datamodel.diffStats.deletions || 0}
          
          Security Issues (top {Math.min(5, ctx.datamodel.securityFindings.length)}):
          {ctx.datamodel.securityFindings.slice(0, 5).map(issue => 
            `- ${issue.severity.toUpperCase()}: ${issue.description} in ${issue.filename} (line ${issue.line})`
          ).join('\n')}
          
          Code Quality Issues (top {Math.min(5, ctx.datamodel.qualityIssues.length)}):
          {ctx.datamodel.qualityIssues.slice(0, 5).map(issue => 
            `- ${issue.severity.toUpperCase()}: ${issue.description} in ${issue.filename} (line ${issue.line})`
          ).join('\n')}
          
          Performance Issues (top {Math.min(5, ctx.datamodel.performanceIssues.length)}):
          {ctx.datamodel.performanceIssues.slice(0, 5).map(issue => 
            `- ${issue.severity.toUpperCase()}: ${issue.description} in ${issue.filename}`
          ).join('\n')}
          
          Test Coverage:
          - Overall coverage: {ctx.datamodel.testCoverage.overall || 0}%
          - Files needing tests: {Object.entries(ctx.datamodel.testCoverage.byFile || {})
              .filter(([_, coverage]) => coverage < 50)
              .map(([file, coverage]) => `${file} (${coverage}%)`)
              .slice(0, 3)
              .join(', ')}
          
          Create a summary that includes:
          1. A concise overview of the code quality
          2. The most critical issues that should be addressed before merging
          3. Minor issues that could be addressed in follow-up PRs
          4. Positive aspects of the code changes
          5. Specific, actionable recommendations
          
          Your summary should be constructive, respectful, and focused on helping the developer improve the code.
        </prompt>
      </llm>
      <assign location="reviewSummary" value={(ctx) => ctx.lastElement.output} />
      <transition target="generateRecommendations" />
  </state>

  <state id="generateRecommendations">
      <llm model="gpt-4o" temperature={0.2}>
        <prompt>
          Based on the analysis of this pull request, generate specific, actionable recommendations 
          to address the identified issues. Focus on clear steps that would help remediate both 
          critical and important problems.
          
          The review identified these categories of issues:
          - Security issues: {ctx.datamodel.securityFindings.length}
          - Code quality issues: {ctx.datamodel.qualityIssues.length}
          - Performance issues: {ctx.datamodel.performanceIssues.length}
          - Test coverage: Overall {ctx.datamodel.testCoverage.overall || 0}%
          
          For each recommendation:
          1. Start with an action verb
          2. Be specific about what should be changed
          3. Explain briefly why this change matters
          4. Provide a simple example or pattern to follow where appropriate
          
          Format your response as a JSON array of recommendation objects, each with:
          - "category": The issue type (security, quality, performance, testing)
          - "priority": A number from 1-3 (1=critical, 2=important, 3=nice-to-have)
          - "recommendation": The specific action to take
          - "rationale": Brief explanation of the benefit
          - "example": Simple example or pattern (when applicable)
          
          Example:
          [
            {
              "category": "security",
              "priority": 1,
              "recommendation": "Sanitize user input in login form",
              "rationale": "Prevents XSS attacks that could steal user credentials",
              "example": "Use built-in sanitization: sanitizeInput(userInput)"
            }
          ]
        </prompt>
      </llm>
      <script>{`
        try {
          ctx.datamodel.recommendations = JSON.parse(ctx.lastElement.output);
          
          // Ensure proper structure
          if (!Array.isArray(ctx.datamodel.recommendations)) {
            throw new Error("Recommendations not in array format");
          }
          
          // Sort by priority
          ctx.datamodel.recommendations.sort((a, b) => a.priority - b.priority);
        } catch (e) {
          ctx.log("Error parsing recommendations: " + e.message);
          ctx.datamodel.recommendations = [
            {
              category: "general",
              priority: 1,
              recommendation: "Review the issues highlighted in the summary",
              rationale: "Addressing these issues will improve code quality",
              example: ""
            }
          ];
        }
      `}</script>
      <log value={(ctx) => 'Generated ' + ctx.datamodel.recommendations.length + ' recommendations'} />
      <transition target="generateFileComments" />
  </state>

  <state id="generateFileComments">
      <forEach item="file" array={ctx => ctx.datamodel.filesToReview}>
        <script>{`
          const fileContent = ctx.datamodel.codeContent[file] || "File content not available";
          const fileChanges = ctx.datamodel.diffContent[file] || "Diff not available";
          ctx.datamodel.currentFile = file;
        `}</script>
        
        <llm model="gpt-4o" temperature={0.3}>
          <prompt>
            Review the following code file changes:
            
            File: {ctx.datamodel.currentFile}
            
            Original changes:
            \`\`\`diff
            {ctx.datamodel.diffContent[ctx.datamodel.currentFile]}
            \`\`\`
            
            Full file content:
            \`\`\`
            {ctx.datamodel.codeContent[ctx.datamodel.currentFile]}
            \`\`\`
            
            Please provide review comments for this file considering:
            
            1. Code quality issues (readability, maintainability, etc.)
            2. Potential bugs or errors
            3. Performance considerations
            4. Security vulnerabilities
            5. Test coverage needs
            
            Also consider the review context:
            - Security Findings: {JSON.stringify(ctx.datamodel.securityFindings)}
            - Quality Issues: {JSON.stringify(ctx.datamodel.qualityIssues)}
            - Performance Issues: {JSON.stringify(ctx.datamodel.performanceIssues)}
            
            Format your response as a JSON object with:
            - summary: Brief summary of changes in the file
            - comments: Array of comment objects with:
              - lineNumber: Line number the comment applies to
              - severity: "high", "medium", or "low"
              - message: The comment text
              - type: "security", "quality", "performance", "testing", or "suggestion"
              - suggestedFix: Code snippet showing how to fix (if applicable)
          </prompt>
        </llm>
        
        <script>{`
          try {
            const reviewResult = JSON.parse(ctx.lastElement.output);
            ctx.datamodel.reviewComments[ctx.datamodel.currentFile] = reviewResult;
          } catch (e) {
            ctx.log(`Error parsing review result for ${ctx.datamodel.currentFile}: ${e.message}`);
            ctx.datamodel.reviewComments[ctx.datamodel.currentFile] = {
              summary: "Error processing review for this file",
              comments: []
            };
          }
        `}</script>
      </forEach>
      <log value={(ctx) => 'Generated comments for ' + Object.keys(ctx.datamodel.reviewComments).length + ' files'} />
      
      <script>{`
        // Prepare the final code review object that will be automatically sent when reaching the final state
        ctx.datamodel.finalReview = {
          "summary": ctx.datamodel.reviewSummary,
          "recommendations": ctx.datamodel.recommendations,
          "detailedComments": ctx.datamodel.reviewComments,
          "stats": {
            "filesChanged": ctx.datamodel.diffStats.filesChanged,
            "linesAdded": ctx.datamodel.diffStats.additions,
            "linesRemoved": ctx.datamodel.diffStats.deletions,
            "securityIssues": ctx.datamodel.securityFindings.length,
            "qualityIssues": ctx.datamodel.qualityIssues.length,
            "performanceIssues": ctx.datamodel.performanceIssues.length,
            "testCoverage": ctx.datamodel.testCoverage.overall
          }
        };
      `}</script>
      
      <transition target="complete" />
  </state>

  <final id="complete" />
</workflow>