---
title: Using AIML with Fireworks
description: Learn how to use AIML with Fireworks AI API
---
import { Banner } from 'fumadocs-ui/components/banner';
import { DynamicCodeBlock } from 'fumadocs-ui/components/dynamic-codeblock';
import { TypeTable } from 'fumadocs-ui/components/type-table';
import { Tabs, Tab } from 'fumadocs-ui/components/tabs';
 
# Using AIML with Fireworks API

This guide will help you run your AIML agents using the Fireworks AI API.

<Banner className="bg-blue-500 text-white rounded-lg">
  Important: Currently requires the `enable-api-preview=true` header to be set while AIML is still in preview.
</Banner>

## Prerequisites

Before you begin, you'll need:

1. A Fireworks AI account
2. An [API key from Fireworks AI](https://fireworks.ai/settings/users/api-keys)
3. Your AIML prompt 

That's it. No Special SDKs or anything. In fact, if you are already using an SDK such as the [Vercel AI SDK](https://sdk.vercel.ai/) or another such tool you absolutely do not need to change anything except adding the `enable-api-preview=true` header and sending the AIML content as a system prompt.
## API Integration

To use AIML with Fireworks, you'll send your AIML content as a system prompt to the Fireworks API. The API will process the AIML workflow and return the results.


### API Examples

Here are examples of how to call the Fireworks API with AIML loaded from a file, assuming you have a file called `my-first-agent.aiml` containing your AIML prompt:

<Tabs items={['cURL', 'JavaScript (Node.js)', 'JavaScript (Bun)', 'Python']}>
<Tab value="cURL">
```bash

# Then use the file in the API call
curl --request POST \
  --url https://api.fireworks.ai/inference/v1/chat/completions \
  --header 'Authorization: Bearer YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --header 'enable-api-preview: true' \
  --data "{
  \"model\": \"accounts/fireworks/models/llama-v3p1-8b-instruct\",
  \"messages\": [
    {
      \"role\": \"system\",
      \"content\": \"$(cat my-first-agent.aiml)\"
    },
    {
      \"role\": \"user\",
      \"content\": \"What is AIML?\"
    }
  ],
}"
```
</Tab>
<Tab value="JavaScript (Node.js)">
```javascript
const fs = require('fs');
const path = require('path');
// For Node.js versions < 18, install node-fetch: npm install node-fetch
// const fetch = require('node-fetch'); // Uncomment for Node.js < 18

// Path to your AIML file
const aimlFilePath = path.join(__dirname, 'my-first-agent.aiml');

// Read the AIML file
const aimlContent = fs.readFileSync(aimlFilePath, 'utf8');

async function callFireworksAPI() {
  try {
    const response = await fetch('https://api.fireworks.ai/inference/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': 'Bearer YOUR_API_KEY',
        'Content-Type': 'application/json',
        'enable-api-preview': 'true'
      },
      body: JSON.stringify({
        "model": "accounts/fireworks/models/llama-v3p1-8b-instruct",
        "messages": [
          {
            "role": "system",
            "content": aimlContent
          },
          {
            "role": "user",
            "content": "What is AIML?"
          }
        ],
      })
    });

    const result = await response.json();
    console.log(result);
  } catch (error) {
    console.error('Error calling Fireworks API:', error);
  }
}

callFireworksAPI();
```
</Tab>
<Tab value="JavaScript (Bun)">
```javascript
import { readFileSync } from 'fs';
import { join } from 'path';

// Path to your AIML file
const aimlFilePath = join(import.meta.dir, 'agent.aiml');

// Read the AIML file
const aimlContent = readFileSync(aimlFilePath, 'utf8');

// Make the API request
const response = await fetch('https://api.fireworks.ai/inference/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json',
    'enable-api-preview': 'true'
  },
  body: JSON.stringify({
    "model": "accounts/fireworks/models/llama-v3p1-8b-instruct",
    "messages": [
      {
        "role": "system",
        "content": aimlContent
      },
      {
        "role": "user",
        "content": "What is AIML?"
      }
    ],
  })
});

const result = await response.json();
console.log(result);
```
</Tab>
<Tab value="Python">
```python
import requests
import os

# Path to your AIML file
aiml_file_path = os.path.join(os.path.dirname(__file__), 'agent.aiml')

# Read the AIML file
with open(aiml_file_path, 'r') as file:
    aiml_content = file.read()

url = "https://api.fireworks.ai/inference/v1/chat/completions"

payload = {
    "model": "accounts/fireworks/models/llama-v3p1-8b-instruct",
    "messages": [
        {
            "role": "system",
            "content": aiml_content
        },
        {
            "role": "user",
            "content": "What is AIML?"
        }
    ],

}

headers = {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json",
    "enable-api-preview": "true"
}

response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
</Tab>
</Tabs>


## Next Steps

- Explore [AIML Elements](./elements/index) for more advanced workflows
- Check out [Examples](./examples/index) for inspiration
- Learn about [Streaming](./elements/stream/index) for real-time responses
